{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz8RRVUluooY"
      },
      "source": [
        "# Nova se√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KBYp2YMiqGO"
      },
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "import re\n",
        "import rdflib\n",
        "from rdflib.graph import Graph\n",
        "from rdflib import URIRef, BNode, Literal\n",
        "from rdflib import Namespace\n",
        "from rdflib.namespace import CSVW, DC, DCAT, DCTERMS, DOAP, FOAF, ODRL2, ORG, OWL, PROF, PROV, RDF, RDFS, SDO, SH, SKOS, SOSA, SSN, TIME, VOID, XMLNS, XSD\n",
        "from rdflib.plugins import sparql\n",
        "import owlrl\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON, XML, N3, TURTLE, JSONLD\n",
        "import unicodedata\n",
        "from texthero import preprocessing\n",
        "import texthero as hero\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "import pandas\n",
        "from difflib import SequenceMatcher\n",
        "from semanticscholar import SemanticScholar\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from scholarly import scholarly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1BtA0s7aoud"
      },
      "source": [
        "# Nova se√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPDwyBbuij-9"
      },
      "outputs": [],
      "source": [
        "def buscaScholar(autor):\n",
        "  dados = []\n",
        "  search_query = scholarly.search_author(autor)\n",
        "  for x in search_query:\n",
        "      dados.append(scholarly.fill(x, sections=['basics', 'indices','publications']))\n",
        "  return dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp8DfXCGVk2_"
      },
      "outputs": [],
      "source": [
        "def buscaInfo(autor,posicao):\n",
        "  date = datetime.date.today()\n",
        "  year = int(date.strftime(\"%Y\")) - 5\n",
        "  autor_dados = scholarly.fill(autor[posicao])\n",
        "  publicacoes = autor_dados['publications']\n",
        "  informacoes = autor_dados\n",
        "  publi= [] \n",
        "  for p in publicacoes:\n",
        "    if not 'pub_year' in  p['bib']:\n",
        "          p['bib']['pub_year'] = '0000'\n",
        "    if int(p['bib']['pub_year']) >= year: \n",
        "      publi.append(scholarly.fill(p))\n",
        "\n",
        "  Autor_Info = {\n",
        " 'nome' : informacoes['name'] ,\n",
        " 'afilicao' : informacoes['affiliation'],\n",
        " 'interesse' : informacoes['interests'],\n",
        " 'hindex' : informacoes['hindex'] ,\n",
        " 'i10' : informacoes['i10index'] ,\n",
        " 'citado' : informacoes['citedby'] ,\n",
        " 'publicacao' : [] ,\n",
        "  }\n",
        "  for x in publi:\n",
        "    if \"journal\" in x['bib']:\n",
        "        if 'pub_year' in  x['bib']:\n",
        "          ano  = x['bib']['pub_year']\n",
        "        else:\n",
        "          ano = '0000'  \n",
        "        Autor_Info['publicacao'].append({\n",
        "                  'title':  x['bib']['title'],\n",
        "                  'pub_year': ano ,\n",
        "                  'tipo_publi': 'journal'  ,\n",
        "                  'veiculo':  x['bib']['journal'],})\n",
        "\n",
        "    if \"conference\" in x['bib']:\n",
        "        if 'pub_year' in  x['bib']:\n",
        "          ano  = x['bib']['pub_year']\n",
        "        else:\n",
        "          ano = '0000'  \n",
        "        Autor_Info['publicacao'].append({\n",
        "                  'title':  x['bib']['title'],\n",
        "                  'pub_year': ano ,\n",
        "                  'tipo_publi': 'conference'  ,\n",
        "                  'veiculo':  x['bib']['conference'],})\n",
        "\n",
        "    if \"Book\" in x['bib']:\n",
        "        if 'pub_year' in  x['bib']:\n",
        "          ano  = x['bib']['pub_year']\n",
        "        else:\n",
        "          ano = '0000'\n",
        "        Autor_Info['publicacao'].append({\n",
        "                  'title':  x['bib']['title'],\n",
        "                  'pub_year':  ano ,\n",
        "                  'tipo_publi': 'Book'  ,\n",
        "                  'veiculo':  x['bib']['Book'],})\n",
        "\n",
        "    if \"volume\" in x['bib']:\n",
        "        if 'pub_year' in  x['bib']:\n",
        "          ano  = x['bib']['pub_year']\n",
        "        else:\n",
        "          ano = '0000'\n",
        "        Autor_Info['publicacao'].append({\n",
        "                  'title':  x['bib']['title'],\n",
        "                  'pub_year':  ano ,\n",
        "                  'tipo_publi': 'volume'  ,\n",
        "                  'veiculo':  x['bib']['volume'],})\n",
        "        \n",
        "  for t in Autor_Info['publicacao']:\n",
        "    if t['veiculo'].isdigit() == True:\n",
        "      del(Autor_Info['publicacao'][Autor_Info['publicacao'].index(t)])\n",
        "  del informacoes[\"publications\"]\n",
        "\n",
        "  return Autor_Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3AI-SaO27Rp"
      },
      "outputs": [],
      "source": [
        "def buscaSemantic(Autor_Info):\n",
        "    titulos = []\n",
        "    sch = SemanticScholar(timeout=5)\n",
        "    for t in Autor_Info['publicacao']:\n",
        "        if_contains_t = t['title']\n",
        "        headers = {'Accept': 'application/json'}\n",
        "        r = \\\n",
        "            requests.get('https://api.semanticscholar.org/graph/v1/paper/search?query='\n",
        "                          + if_contains_t + '&fields=title,authors',\n",
        "                         headers=headers)\n",
        "        data = r.json()\n",
        "        #if data['total'] >= 1:\n",
        "        for x in data['data'][0]['authors']:\n",
        "                    result = SequenceMatcher(None, x['name'],\n",
        "                            Autor_Info['nome']).ratio()\n",
        "                    if result > 0.6:\n",
        "                        semantic_dados = sch.author(x['authorId'])\n",
        "        \n",
        "                        for t in Autor_Info['publicacao']:\n",
        "                            titulos.append(t['title'].lower())\n",
        "\n",
        "                        for t in semantic_dados['papers']:\n",
        "                            match = process.extract(t['title'].lower(), titulos,\n",
        "                                                    scorer=fuzz.token_sort_ratio)\n",
        "                            if match[0][1] < 60:\n",
        "                                paperid = str(t['paperId'])\n",
        "                                paper = sch.paper(paperid)\n",
        "                                Autor_Info['publicacao'].append({'title': paper['title'],\n",
        "                                        'pub_year': paper['year'], 'veiculo': paper['venue'\n",
        "                                        ]})\n",
        "                                \n",
        "                    return Autor_Info\n",
        "                    break\n",
        "                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lySAsvnk9H9g"
      },
      "outputs": [],
      "source": [
        "def qualis (Autor_Info):\n",
        "\n",
        "  _pr = pandas.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRqi1UUf_cTEj1B4VWMCHk3fhzcMQgsyH3jSox1m-G6CuOuUniUuLc8GK6yjMY4CnUWZd_V77sCuYut/pub?output=csv')\n",
        "  _pr['√Årea de Avalia√ß√£o'] = _pr['√Årea de Avalia√ß√£o'].str.strip()\n",
        "  _pr['√Årea de Avalia√ß√£o'].tolist()\n",
        "  _pr['Estrato'] = _pr['Estrato'].str.strip()\n",
        "  _pr['Estrato'].tolist()\n",
        "  \n",
        "  pr = _pr.loc[_pr['√Årea de Avalia√ß√£o'].values == 'CI√äNCIA DA COMPUTA√á√ÉO'] \n",
        "  pr = pr.reset_index(drop=True)\n",
        "\n",
        "  cn = pandas.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT7FcK0i4UN6ULcLFlEa7FO2E0vemz-9VfIwEtaOW6PnP4eAzCyzJ1BPwtATk0ZKUKVBvHaT5Mx2TBV/pub?output=csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #conferencia_link = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTZsntDnttAWGHA8NZRvdvK5A_FgOAQ_tPMzP7UUf-CHwF_3PHMj_TImyXN2Q_Tmcqm2MqVknpHPoT2/pubhtml?gid=0&single=true'\n",
        "  #res = requests.get(conferencia_link)\n",
        "  #soup = BeautifulSoup(res.content, 'lxml')\n",
        "  #conferencias = pandas.read_html(str(soup))\n",
        "  #c = {'sigla': conferencias[0]['Unnamed: 1'],\n",
        "      #    'conferencia': conferencias[0]['Unnamed: 2'],\n",
        "       #   'Qualis_Final': conferencias[0]['Unnamed: 7']}\n",
        "  #cn = pandas.DataFrame(data=c)\n",
        "\n",
        "  #cn = pandas.DataFrame(data=c).dropna()\n",
        "\n",
        "  #cn = cn.drop(0)\n",
        " # pr = pr.drop(0)\n",
        "\n",
        "  custom_pipeline = [preprocessing.fillna, \n",
        "                        preprocessing.lowercase,\n",
        "                        preprocessing.remove_whitespace,\n",
        "                        preprocessing.remove_punctuation]\n",
        "  cn['conferencia_limpo'] = hero.clean(cn['conferencia'],\n",
        "              custom_pipeline)\n",
        "  pr['periodicos_limpo'] = hero.clean(pr['T√≠tulo'],\n",
        "              custom_pipeline)\n",
        "\n",
        "  con = cn['conferencia_limpo'].values.tolist()\n",
        "  per = pr['periodicos_limpo'].values.tolist()\n",
        "\n",
        "  for i in Autor_Info['publicacao']:\n",
        "\n",
        "          \n",
        "          peri = process.extractOne(i['veiculo'],\n",
        "                                   pr['periodicos_limpo'],\n",
        "                                    scorer=fuzz.token_set_ratio)\n",
        "          conf = process.extractOne(i['veiculo'],\n",
        "                                    cn['conferencia_limpo'],\n",
        "                                    scorer=fuzz.token_set_ratio)\n",
        "\n",
        "          \n",
        "          if peri[1] > conf[1] : \n",
        "            if peri[1] >= 95:\n",
        "                df_mask=pr['periodicos_limpo'] == str(peri[0])\n",
        "                filtered_df = pr[df_mask]\n",
        "                i['Qualis'] = str(filtered_df.iat[0,3])\n",
        "                #i['veiculo'] = str(filtered_df.iat[0,1])\n",
        "                i['inss'] = str(filtered_df.iat[0,0])\n",
        "                i['tipo_evento'] = 'periodico'\n",
        "          else:\n",
        "            if conf[1] >= 95:\n",
        "              df_mask=cn['conferencia_limpo'] == str(conf[0])\n",
        "              filtered_df = cn[df_mask]\n",
        "              i['Qualis'] = str(filtered_df.iat[0,6])\n",
        "              #i['veiculo'] = str(filtered_df.iat[0,3])\n",
        "              i['sigla'] = str(filtered_df.iat[0,0])\n",
        "              i['tipo_evento'] = 'conferencia'\n",
        "\n",
        "  return Autor_Info     \n",
        "\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1kAaCpP268c"
      },
      "outputs": [],
      "source": [
        "def clear_char(palavra):\n",
        "\n",
        "    # Unicode normalize transforma um caracter em seu equivalente em latin.\n",
        "    nfkd = unicodedata.normalize('NFKD', palavra)\n",
        "    palavraSemAcento = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
        "\n",
        "    # Usa express√£o regular para retornar a palavra apenas com n√∫meros, letras e espa√ßo\n",
        "    return re.sub('[^a-zA-Z0-9 \\\\\\]', '', palavraSemAcento)\n",
        "\n",
        "\n",
        "def gera_ontologia(base_principal):\n",
        "  date = datetime.date.today()\n",
        "  year = str(int(date.strftime(\"%Y\")) - 5) \n",
        "  dic={}\n",
        "  p = []\n",
        "  e= []\n",
        "  g = Graph()\n",
        "  n3data = \"\"\"@prefix : <http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#> .\n",
        "  @prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
        "  @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
        "  @prefix xml: <http://www.w3.org/XML/1998/nomespace> .\n",
        "  @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
        "  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
        "  @base <http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao> .\n",
        "\n",
        "  <http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao> rdf:type owl:Ontology .\n",
        "\n",
        "  #################################################################\n",
        "  #    Object Properties\n",
        "  #################################################################\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Afiliado\n",
        "  :Afiliado rdf:type owl:ObjectProperty ;\n",
        "            rdfs:domain :Autor_Cientifico ;\n",
        "            rdfs:range :Instituicao .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Classificada\n",
        "  :Classificada rdf:type owl:ObjectProperty ;\n",
        "                rdfs:domain :Veiculo ;\n",
        "                rdfs:range :Qualis .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Detem\n",
        "  :Detem rdf:type owl:ObjectProperty ;\n",
        "        rdfs:domain :Autor_Cientifico ;\n",
        "        rdfs:range :Autoria_Cientifica .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Pesquisa\n",
        "  :Pesquisa rdf:type owl:ObjectProperty ;\n",
        "            rdfs:domain :Autor_Cientifico ;\n",
        "            rdfs:range :Area_Pesquisa .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Publicado_em\n",
        "  :Publicado_em rdf:type owl:ObjectProperty ;\n",
        "                rdfs:domain :Publicacao ;\n",
        "                rdfs:range :Veiculo .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Refere_se\n",
        "  :Refere_se rdf:type owl:ObjectProperty ;\n",
        "            rdfs:domain :Autoria_Cientifica ;\n",
        "            rdfs:range :Texto_Autoral_Cientifico_Publicado .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Submetido\n",
        "  :Submetido rdf:type owl:ObjectProperty ;\n",
        "            rdfs:domain :Texto_Autoral_Cientifico_Publicado ;\n",
        "            rdfs:range :Publicacao .\n",
        "\n",
        "\n",
        "  #################################################################\n",
        "  #    Data properties\n",
        "  #################################################################\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Area_Pesquisa\n",
        "  :Area_Pesquisa rdf:type owl:DatatypeProperty ;\n",
        "                rdfs:domain :Area_Pesquisa .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Autor_Citacao\n",
        "  :Autor_Citacao rdf:type owl:DatatypeProperty ;\n",
        "                rdfs:domain :Autor_Cientifico .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Autor_IndiceH\n",
        "  :Autor_IndiceH rdf:type owl:DatatypeProperty ;\n",
        "                rdfs:domain :Autor_Cientifico .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Autor_indiceI10\n",
        "  :Autor_indiceI10 rdf:type owl:DatatypeProperty ;\n",
        "                  rdfs:domain :Autor_Cientifico .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Edicao_Ano\n",
        "  :Edicao_Ano rdf:type owl:DatatypeProperty ;\n",
        "              rdfs:domain :Veiculo .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Edicao_Nome\n",
        "  :Edicao_Nome rdf:type owl:DatatypeProperty ;\n",
        "              rdfs:domain :Veiculo .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Edicao_Tipo\n",
        "  :Edicao_Tipo rdf:type owl:DatatypeProperty ;\n",
        "              rdfs:domain :Veiculo .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Instituicao\n",
        "  :Instituicao rdf:type owl:DatatypeProperty ;\n",
        "              rdfs:domain :Instituicao .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Nome_Autor\n",
        "  :Nome_Autor rdf:type owl:DatatypeProperty ;\n",
        "              rdfs:domain :Autor_Cientifico .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Publicacao_Citacao\n",
        "  :Publicacao_Citacao rdf:type owl:DatatypeProperty ;\n",
        "                      rdfs:domain :Publicacao .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Qualis_Extrato\n",
        "  :Qualis_Extrato rdf:type owl:DatatypeProperty ;\n",
        "                  rdfs:domain :Qualis .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Titulo_Artigo\n",
        "  :Titulo_Artigo rdf:type owl:DatatypeProperty ;\n",
        "                rdfs:domain :Texto .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Veiculo_Codigo\n",
        "  :Veiculo_Codigo rdf:type owl:DatatypeProperty ;\n",
        "                  rdfs:domain :Veiculo .\n",
        "\n",
        "\n",
        "  #################################################################\n",
        "  #    Classes\n",
        "  #################################################################\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Area_Pesquisa\n",
        "  :Area_Pesquisa rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Autor_Cientifico\n",
        "  :Autor_Cientifico rdf:type owl:Class ;\n",
        "                    rdfs:subClassOf :Pessoa .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Autoria_Cientifica\n",
        "  :Autoria_Cientifica rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Instituicao\n",
        "  :Instituicao rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Pessoa\n",
        "  :Pessoa rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Publicacao\n",
        "  :Publicacao rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Qualis\n",
        "  :Qualis rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Texto\n",
        "  :Texto rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Texto_Autoral_Cientifico_Publicado\n",
        "  :Texto_Autoral_Cientifico_Publicado rdf:type owl:Class ;\n",
        "                                      rdfs:subClassOf :Texto .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#Veiculo\n",
        "  :Veiculo rdf:type owl:Class .\n",
        "\n",
        "\n",
        "  #################################################################\n",
        "  #    Individuals\n",
        "  #################################################################\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#A1\n",
        "  :A1 rdf:type owl:nomedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"A1\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#A2\n",
        "  :A2 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"A2\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#A3\n",
        "  :A3 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"A3\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#A4\n",
        "  :A4 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"A4\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#B1\n",
        "  :B1 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"B1\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#B2\n",
        "  :B2 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"B2\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#B3\n",
        "  :B3 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"B3\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#B4\n",
        "  :B4 rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "      :Qualis_Extrato \"B4\" .\n",
        "\n",
        "\n",
        "  ###  http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#C\n",
        "  :C rdf:type owl:NamedIndividual ,\n",
        "              :Qualis ;\n",
        "    :Qualis_Extrato \"C\" .\n",
        "\n",
        "\n",
        "  ###  Generated by the OWL API (version 4.5.9.2019-02-01T07:24:44Z) https://github.com/owlcs/owlapi\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  ontologia = g.parse(data=n3data, format='ttl')\n",
        "  pp  = Namespace(\"http://www.semanticweb.org/fantasma/ontologies/2021/10/Publicacao#\")#iri\n",
        "  g.bind(\"pp\", pp )\n",
        "  nome_autor = base_principal['nome']\n",
        "  Interesses_autor = base_principal['interesse']\n",
        "  Afilia√ß√£o_autor = base_principal['afilicao']\n",
        "  nome_autor_limpo = re.sub('[,|\\s]+', '_', clear_char(nome_autor))\n",
        "  Afiliacao_autor_limpo = re.sub('[,|\\s]+', '_', clear_char(Afilia√ß√£o_autor))\n",
        "\n",
        "  #dados do autor \n",
        "  g.add((pp[nome_autor_limpo], RDF.type, pp.Autor_Cientifico))\n",
        "  g.add((pp[nome_autor_limpo], pp.Nome_Autor, Literal(base_principal['nome'])))\n",
        "  g.add((pp[nome_autor_limpo], pp.Autor_Citacao, Literal(base_principal['citado'])))\n",
        "  g.add((pp[nome_autor_limpo], pp.Autor_IndiceH, Literal(base_principal['hindex'])))\n",
        "  g.add((pp[nome_autor_limpo], pp.Autor_indiceI10, Literal(base_principal['i10'])))\n",
        "\n",
        "\n",
        "  g.add((pp[Afiliacao_autor_limpo], RDF.type, pp.Instituicao))\n",
        "  g.add((pp[Afiliacao_autor_limpo], pp.Instituicao, Literal(Afilia√ß√£o_autor)))\n",
        "\n",
        "  g.add((pp[nome_autor_limpo], pp.Afiliado, pp[Afiliacao_autor_limpo]))\n",
        "\n",
        "  #area de interesse\n",
        "  for x in Interesses_autor:\n",
        "      area = re.sub('[,|\\s]+', '_', clear_char(x))\n",
        "\n",
        "      g.add((pp[area], RDF.type, pp.Area_Pesquisa))\n",
        "      g.add((pp[area], pp.Area_Pesquisa, Literal(x)))\n",
        "      g.add((pp[nome_autor_limpo], pp.Pesquisa, pp[area]))\n",
        "\n",
        "  #publicacao\n",
        "\n",
        "      \n",
        "    \n",
        "  for x in range(len(base_principal['publicacao'])):\n",
        "      titulo = base_principal['publicacao'][x]['title']\n",
        "      titulo_clean = re.sub('[,|\\s]+', '_', clear_char(titulo))\n",
        "      veiculo =  base_principal['publicacao'][x]['veiculo']\n",
        "      veiculo_clean = re.sub('[,|\\s]+', '_', clear_char( veiculo))\n",
        "      autoria = nome_autor_limpo +'_Autoria_'+str(x)\n",
        "      publicacao = nome_autor_limpo +'_Publicacao_'+str(x)\n",
        "     \n",
        "      #Cria Autoria \n",
        "      g.add((pp[autoria], RDF.type, pp.Autoria_Cientifica))\n",
        "      g.add((pp[nome_autor_limpo], pp.Detem, pp[autoria]))\n",
        "      \n",
        "      #Cria Artigo\n",
        "      g.add((pp[titulo_clean], RDF.type, pp.Texto_Autoral_Cientifico_Publicado))\n",
        "      g.add((pp[titulo_clean], pp.Titulo_Artigo, Literal(titulo)))\n",
        "\n",
        "      g.add((pp[autoria], pp.Refere_se, pp[titulo_clean]))\n",
        "      #Cria Publicacao \n",
        "      g.add((pp[publicacao], RDF.type, pp.Publicacao))\n",
        "      g.add((pp[titulo_clean], pp.Submetido, pp[publicacao]))\n",
        "      g.add((pp[veiculo_clean], RDF.type, pp.Veiculo))\n",
        "      g.add((pp[veiculo_clean], pp.Edicao_Ano, Literal(base_principal['publicacao'][x]['pub_year'])))\n",
        "      g.add((pp[veiculo_clean], pp.Edicao_Nome, Literal(veiculo)))\n",
        "      g.add((pp[publicacao], pp.Publicado_em , pp[veiculo_clean]))  \n",
        "\n",
        "\n",
        "      if 'Qualis' in base_principal['publicacao'][x]:\n",
        "          qualis = base_principal['publicacao'][x]['Qualis']\n",
        "          #qualis_clear = re.sub('[,|\\s]+', '_', clear_char(qualis))\n",
        "          g.add((pp[veiculo_clean], pp.Classificada, pp[qualis]))\n",
        "          g.add((pp[veiculo_clean], pp.Edicao_Tipo, Literal(base_principal['publicacao'][x]['tipo_publi'])))\n",
        "      else: \n",
        "          #g.add((pp[veiculo_clean], pp.Classificada, pp[\"C\"]))\n",
        "          g.add((pp[veiculo_clean], pp.Edicao_Tipo, Literal('N√£o Especificado')))\n",
        "\n",
        "\n",
        "  #g.serialize(data = ontologia, format='turtle')\n",
        "  qres = g.query(\n",
        "    \"\"\"SELECT ?titulo ?q ?evento ?tipo\n",
        "      WHERE\n",
        "        { \n",
        "         ?artigo a pp:Texto_Autoral_Cientifico_Publicado;\n",
        "              pp:Titulo_Artigo ?titulo.\n",
        "         ?artigo pp:Submetido ?y.\n",
        "          ?y pp:Publicado_em ?evento.\n",
        "          ?evento  pp:Edicao_Tipo ?tipo.\n",
        "          ?evento  pp:Edicao_Ano ?data.\n",
        "            FILTER (?data >= \"\"\"+year+\"\"\")\n",
        "          ?evento pp:Classificada ?qualis.\n",
        "         ?qualis pp:Qualis_Extrato ?q.\n",
        "         }\"\"\")\n",
        "  \n",
        "  #Colocar filtro por nome.\n",
        "  #SELECT ?titulo ?q ?evento ?tipo\n",
        "      #WHERE\n",
        "        #{ \n",
        "        # ?artigo a pp:Texto_Autoral_Cientifico_Publicado;\n",
        "          #    pp:Titulo_Artigo ?titulo.\n",
        "        # ?artigo pp:Submetido ?y.\n",
        "          #?y pp:Publicado_em ?evento.\n",
        "          #?evento  pp:Edicao_Tipo ?tipo.  \n",
        "          #?evento pp:Classificada ?qualis.\n",
        "        # ?qualis pp:Qualis_Extrato ?q.}\n",
        "\n",
        "  for row in qres:\n",
        "        d = {\n",
        "        'Titulo' : re.search(\"([^']*)\",str(row.titulo)).string,\n",
        "        'Evento': re.search(\"([^']*)\",str(row.evento)).string,\n",
        "        'Tipo' : re.search(\"([^']*)\",str(row.tipo)).string,\n",
        "        'Qualis': re.search(\"([^']*)\",str(row.q)).string,}\n",
        "        p.append(d)\n",
        "  for x in range(len(p)):\n",
        "        if p[x]['Tipo'] == 'journal' :\n",
        "            if  p[x]['Qualis'] == 'A1':\n",
        "                p[x][ 'Pontua√ß√£o'] = 1.000\n",
        "\n",
        "            if p[x]['Qualis'] == 'A2':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.875\n",
        "\n",
        "            if p[x]['Qualis'] == 'A3':\n",
        "                p[x][ 'Pontua√ß√£o'] = 0.750\n",
        "\n",
        "            if p[x]['Qualis'] == 'A4':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.625\n",
        "\n",
        "            if p[x]['Qualis'] == 'B1':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.500\n",
        "\n",
        "            if p[x]['Qualis'] == 'B2':\n",
        "                p[x][ 'Pontua√ß√£o'] = 0.200\n",
        "\n",
        "            if p[x]['Qualis'] == 'B3':\n",
        "                d[ 'Pontua√ß√£o'] =  0.100\n",
        "\n",
        "            if p[x]['Qualis'] == 'B4':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.050\n",
        "            if p[x]['Qualis'] == 'C':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.000   \n",
        "        if p[x]['Tipo'] == 'conference':\n",
        "            if p[x]['Qualis'] == 'A1':\n",
        "                p[x][ 'Pontua√ß√£o'] = 1.000\n",
        "              \n",
        "            if p[x]['Qualis'] == 'A2':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.875\n",
        "\n",
        "            if p[x]['Qualis'] == 'A3':\n",
        "                p[x][ 'Pontua√ß√£o'] = 0.750\n",
        "\n",
        "            if p[x]['Qualis'] == 'A4':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.625\n",
        "\n",
        "            if p[x]['Qualis'] == 'B1':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.500\n",
        "\n",
        "            if p[x]['Qualis'] == 'B2':\n",
        "                p[x][ 'Pontua√ß√£o'] = 0.200\n",
        "\n",
        "            if p[x]['Qualis'] == 'B3':\n",
        "                p[x][ 'Pontua√ß√£o'] = 0.100\n",
        "\n",
        "            if p[x]['Qualis'] == 'B4':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.050\n",
        "            if p[x]['Qualis'] == 'C':\n",
        "                p[x][ 'Pontua√ß√£o'] =  0.000   \n",
        "\n",
        "  data_qualis = pandas.DataFrame(data=p)\n",
        "  s = g.serialize(format='turtle')\n",
        "  with open(\"Ontologia_Publicacao\"+\".ttl\", 'w') as f:\n",
        "      f.write(s)\n",
        "  return data_qualis    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9q8eSce1hZM"
      },
      "source": [
        "# Nova se√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXLh9qABwoKn"
      },
      "outputs": [],
      "source": [
        "import panel as pn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eUoJYJEYwtOU",
        "outputId": "a7d77bb3-d8cb-4fca-98f8-d0231111c9ee"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      \n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.1/dist/css/loading.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pn.extension()\n",
        "df = pandas.DataFrame()\n",
        "w1 = pn.widgets.TextInput(name='Text:')\n",
        "search = pn.widgets.Button(name='üîç', width=100)\n",
        "search2 = pn.widgets.Button(name='üîç2', width=100)\n",
        "select = pn.widgets.Select(name='Select')\n",
        "autor = []\n",
        "\n",
        "def b(event):\n",
        "  autores = []\n",
        "  dados = buscaScholar(w1.value)\n",
        "\n",
        "  for x in dados:\n",
        "    autores.append (x['name']) \n",
        "    autor.append(x)\n",
        "  select.options = autores\n",
        "\n",
        "def b2(event):\n",
        "  posit = select.options.index(select.value)\n",
        "  info = buscaInfo(autor,int(posit))\n",
        "  semantic = buscaSemantic(info)\n",
        "  base_principal = qualis(semantic)\n",
        "  base = gera_ontologia(base_principal)\n",
        "  dat = pn.widgets.DataFrame(base, name='DataFrame')\n",
        "  display(dat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PiKl_6RwtJv"
      },
      "outputs": [],
      "source": [
        "search.on_click(b)\n",
        "search2.on_click(b2)\n",
        "pn.Column(w1, search,select,search2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "integra√ßao final .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
